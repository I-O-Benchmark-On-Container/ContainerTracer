/****************************************************************************
 * Block I/O Trace Replayer 
 * Yongseok Oh (ysoh@uos.ac.kr) 2013 - 2014

 *  This program is free software; you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation; under version 2 of the License.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
****************************************************************************/

#include <stdio.h>
#include <fcntl.h>
#include <string.h>
#include <stdlib.h>
#include <unistd.h>
#include <jemalloc/jemalloc.h>
#include <pthread.h>
#include <libaio.h>
#include <errno.h>
#include <signal.h>

#include <sys/mount.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <sys/ioctl.h>
#include <sys/time.h>
#include <sys/ipc.h>
#include <sys/msg.h>
#include <sys/shm.h>
#include <sys/sem.h>

#include <flist.h>
#include <trace_replay.h>
#include <disk_io.h>

#define REFRESH_SLEEP 1000000

FILE *log_fp;
FILE *json_fp;
unsigned int log_count = 0;
struct thread_info_t th_info[MAX_THREADS];
struct trace_info_t traces[MAX_THREADS];
struct total_results total_results;
pthread_t threads[MAX_THREADS];
int qdepth;
int cnt = 0;
int cnt2 = 0;
int nr_thread;
int nr_trace;
unsigned int io_size; // in bytes
struct timeval tv_start, tv_end, tv_result, tv_start2;
double execution_time = 0.0;
double timeout;
long long wanted_io_count;
char key_pathname[BASE_KEY_PATHNAME_LEN];

void sgenrand(unsigned long seed);
unsigned long genrand();
#define RND(x) ((x > 0) ? (genrand() % (x)) : 0)

//#define USE_RAND_BUF

#ifdef USE_RAND_BUF
char *g_buf;
#endif

int timeval_subtract(result, x, y) struct timeval *result, *x, *y;
{
        /* Perform the carry for the later subtraction by
		 * updating y. */
        if (x->tv_usec < y->tv_usec) {
                int nsec = (y->tv_usec - x->tv_usec) / 1000000 + 1;
                y->tv_usec -= 1000000 * nsec;
                y->tv_sec += nsec;
        }
        if (x->tv_usec - y->tv_usec > 1000000) {
                int nsec = (y->tv_usec - x->tv_usec) / 1000000;
                y->tv_usec += 1000000 * nsec;
                y->tv_sec -= nsec;
        }

        /* Compute the time remaining to wait.
		 * tv_usec  is certainly positive. */
        result->tv_sec = x->tv_sec - y->tv_sec;
        result->tv_usec = x->tv_usec - y->tv_usec;

        /* Return 1 if result is negative. */
        return x->tv_sec < y->tv_sec;
}

// generated by Eunjae
static double time_since_ms(struct timeval *start_tv, struct timeval *stop_tv)
{
        double sec, usec;
        double ret;
        sec = stop_tv->tv_sec - start_tv->tv_sec;
        usec = stop_tv->tv_usec - start_tv->tv_usec;
        if (sec > 0 && usec < 0) {
                sec--;
                usec += 1000000;
        }
        ret = sec * 1000 + usec / (double)1000;
        if (ret < 0)
                ret = 0;
        return ret;
}

static double time_since(struct timeval *start_tv, struct timeval *stop_tv)
{
        double sec, usec;
        double ret;
        sec = stop_tv->tv_sec - start_tv->tv_sec;
        usec = stop_tv->tv_usec - start_tv->tv_usec;
        if (sec > 0 && usec < 0) {
                sec--;
                usec += 1000000;
        }
        ret = sec + usec / (double)1000000;
        if (ret < 0)
                ret = 0;
        return ret;
}

/* allocate a alignment-bytes aligned buffer */
void *allocate_aligned_buffer(size_t size)
{
        void *p;

        posix_memalign(&p, getpagesize(), size);

        if (!p) {
                perror("memalign");
                exit(0);
                return NULL;
        }

        return p;
}

void align_sector(struct thread_info_t *t_info, int *blkno, int *bcount)
{
        struct trace_info_t *trace = t_info->trace;
        int pageno = *blkno / SPP;
        int pcount;

        pageno %= trace->total_pages;

        if (*bcount % SPP) {
                pcount = *bcount / SPP + 1;
                *bcount = pcount * SPP;
        }
        if (*bcount % SPP) {
                printf(" bcount error %d \n", *bcount % SPP);
        }
        pcount = *bcount / SPP;

        if (pageno + pcount >= trace->total_pages) {
                pageno -= pcount;
        }

        *blkno = pageno * SPP;
}

void update_iostat(struct thread_info_t *t_info, struct io_job *job)
{
        struct io_stat_t *io_stat = &t_info->io_stat;
        double latency;
        unsigned int count;

        gettimeofday(&job->stop_time, NULL);

        pthread_spin_lock(&io_stat->stat_lock);

        latency = time_since(&job->start_time, &job->stop_time);

        io_stat->latency_sum += latency;
        io_stat->latency_sum_sqr += (latency * latency);

        if (!io_stat->latency_count) {
                io_stat->latency_min = latency;
                io_stat->latency_max = latency;
        }

        if (latency < io_stat->latency_min)
                io_stat->latency_min = latency;

        if (latency > io_stat->latency_max)
                io_stat->latency_max = latency;

        io_stat->latency_count++;
        count = io_stat->latency_count;

        io_stat->total_bytes += job->bytes;
        if (job->rw)
                io_stat->total_rbytes += job->bytes;
        else
                io_stat->total_wbytes += job->bytes;

        io_stat->cur_bytes += job->bytes;
        if (job->rw)
                io_stat->cur_rbytes += job->bytes;
        else
                io_stat->cur_wbytes += job->bytes;

        pthread_spin_unlock(&io_stat->stat_lock);

        if (count && t_info->fsync_period &&
            (count % (t_info->fsync_period) == 0)) {
                fsync(t_info->fd);
        }
}

struct simple_bio {
        int devno;
        int blkno;
        int bcount;
        int flags;
};

void trace_reset(struct trace_info_t *trace)
{
        trace->trace_io_cur = 0;
}

int trace_set_eof(struct trace_info_t *trace)
{
        int res = 0;

        pthread_spin_lock(&trace->trace_lock);
        trace->trace_io_cur = trace->trace_io_cnt;
        trace->trace_io_issue_count = trace->wanted_io_count;
        trace->timeout = 0;
        pthread_spin_unlock(&trace->trace_lock);

        printf(" set eof ... \n");
        return res;
}

int trace_eof(struct trace_info_t *trace)
{
        int res = 0;

        pthread_spin_lock(&trace->trace_lock);
        if (trace->trace_io_cnt && trace->trace_io_cur >= trace->trace_io_cnt) {
                res = 1;
        }
        if (trace->wanted_io_count &&
            trace->trace_io_issue_count >= trace->wanted_io_count) {
                res = 1;
        }
        pthread_spin_unlock(&trace->trace_lock);

        if (res)
                printf(" eof ... \n");
        return res;
}

int try_trace_reset(struct trace_info_t *trace, struct io_stat_t *io_stat)
{
        int res = 0;
        if (trace->timeout && io_stat->execution_time < trace->timeout) {
                trace->trace_repeat_count++;
                trace_reset(trace);
                synthetic_mix(trace);
        } else if (trace->wanted_io_count &&
                   trace->trace_io_issue_count < trace->wanted_io_count) {
                trace->trace_repeat_count++;
                trace_reset(trace);
                synthetic_mix(trace);
        } else if (trace->trace_repeat_num &&
                   trace->trace_repeat_count < trace->trace_repeat_num) {
                trace->trace_repeat_count++;
                trace_reset(trace);
                synthetic_mix(trace);
        } else {
                res = -1;
        }

        return res;
}

int trace_io_get(double *arrival_time, int *devno, int *blkno, int *bcount,
                 int *flags, struct trace_info_t *trace,
                 struct io_stat_t *io_stat)
{
        struct trace_io_req *io;

        int res = 0;

        io = &(trace->trace_buf[trace->trace_io_cur]);

        *arrival_time = io->arrival_time;
        *devno = io->devno;
        *bcount = io->bcount;
        *blkno = io->blkno;
        *flags = io->flags;
        trace->trace_io_cur++;
        trace->trace_io_issue_count++;

        if (trace->timeout == 0.0 && trace->wanted_io_count &&
            trace->trace_io_issue_count >= trace->wanted_io_count) {
                res = try_trace_reset(trace, io_stat);
        } else if (trace->trace_io_cur >= trace->trace_io_cnt) {
                res = try_trace_reset(trace, io_stat);
        }

        return res;
}

static void io_done(io_context_t ctx, struct iocb *iocb, long res, long res2)
{
        /* library needs accessors to look at iocb? */
        printf("io_done\n");
}

int make_jobs(struct thread_info_t *t_info, struct iocb **ioq,
              struct io_job **jobq, int depth)
{
        struct io_job *job;
        double arrival_time;
        int devno;
        int blkno;
        int bcount;
        int flags;
        struct io_stat_t *io_stat = &t_info->io_stat;
        int cnt = 0;

        for (; cnt < depth; cnt++) {
                struct trace_info_t *trace = t_info->trace;
                struct timeval tv_now;
                double now, tmp;
                struct trace_io_req *io;

                gettimeofday(&tv_now, NULL);
                now = time_since_ms(&tv_start2, &tv_now);

                pthread_spin_lock(&trace->trace_lock);
                io = &(trace->trace_buf[trace->trace_io_cur]);

                // generated by Eunjae
                if (now < io->arrival_time * trace->trace_timescale) {
                        pthread_spin_unlock(&trace->trace_lock);
                        return cnt;
                }
                if (trace_io_get(&arrival_time, &devno, &blkno, &bcount, &flags,
                                 t_info->trace, io_stat)) {
                        pthread_spin_unlock(&trace->trace_lock);
                        return cnt;
                }
                pthread_spin_unlock(&trace->trace_lock);

                job = (struct io_job *)malloc(sizeof(struct io_job));
                align_sector(t_info, &blkno, &bcount);
                job->offset = (long long)blkno * SECTOR_SIZE;
                job->bytes = (size_t)bcount * SECTOR_SIZE;
                if (job->bytes > (size_t)MAX_BYTES)
                        job->bytes = MAX_BYTES;

                if (flags)
                        job->rw = 1;
                else
                        job->rw = 0;

                job->buf = allocate_aligned_buffer(job->bytes);

                gettimeofday(&job->start_time, NULL);

                job->offset += trace->start_partition;
                ioq[cnt] = &job->iocb;
                jobq[cnt] = job;

                gettimeofday(&tv_now, NULL);
                now = time_since_ms(&tv_start2, &tv_now);
                tmp = now - arrival_time * trace->trace_timescale;
                tmp = (tmp > 0) ? tmp : tmp * (-1.0);
                pthread_spin_lock(&io_stat->stat_lock);
                io_stat->time_diff += tmp;
                io_stat->time_diff_cnt++;
                pthread_spin_unlock(&io_stat->stat_lock);
#ifndef USE_RAND_BUF
                if (job->rw)
                        io_prep_pread(&job->iocb, t_info->fd, job->buf,
                                      job->bytes, job->offset);
                else
                        io_prep_pwrite(&job->iocb, t_info->fd, job->buf,
                                       job->bytes, job->offset);
#else
                if (job->rw)
                        io_prep_pread(&job->iocb, t_info->fd, g_buf, job->bytes,
                                      job->offset);
                else
                        io_prep_pwrite(&job->iocb, t_info->fd, g_buf,
                                       job->bytes, job->offset);

#endif
                io_set_callback(&job->iocb, io_done);
        }

        return cnt;
}

// generated by Eunjae
void wait_arrive(struct thread_info_t *t_info)
{
        struct timeval tv_now;
        double now;
        double sleep_ms;
        struct trace_io_req *io;

        struct trace_info_t *trace = t_info->trace;

        gettimeofday(&tv_now, NULL);
        now = time_since_ms(&tv_start2, &tv_now);

        pthread_spin_lock(&trace->trace_lock);
        io = &(trace->trace_buf[trace->trace_io_cur]);

        if (trace->timeout > 0.0) {
                sleep_ms = io->arrival_time * trace->trace_timescale - now;
                if (sleep_ms > trace->timeout * 1000 - now) {
                        sleep_ms = trace->timeout * 1000 - now;
                }
        } else {
                sleep_ms = io->arrival_time * trace->trace_timescale - now;
        }

        while (sleep_ms > 0) {
                pthread_spin_unlock(&trace->trace_lock);
                usleep(sleep_ms * 1000);
                pthread_spin_lock(&trace->trace_lock);
                gettimeofday(&tv_now, NULL);
                now = time_since_ms(&tv_start2, &tv_now);

                if (trace->timeout > 0.0) {
                        sleep_ms =
                                io->arrival_time * trace->trace_timescale - now;
                        if (sleep_ms > trace->timeout * 1000 - now) {
                                sleep_ms = trace->timeout * 1000 - now;
                        }
                } else {
                        sleep_ms =
                                io->arrival_time * trace->trace_timescale - now;
                }

                io = &(trace->trace_buf[trace->trace_io_cur]);
        }
        pthread_spin_unlock(&trace->trace_lock);
}

void wait_completion(struct thread_info_t *t_info, int cnt)
{
        struct io_job *job;
        int i;

        while (1) {
                int complete_count = io_getevents(t_info->io_ctx, 1, cnt,
                                                  t_info->events, NULL);
                if (complete_count <= 0) {
                        continue;
                }
                for (i = 0; i < complete_count; i++) {
                        job = (struct io_job *)((unsigned long)t_info->events[i]
                                                        .obj);
                        update_iostat(t_info, job);

                        free(job->buf);
                        free(job);
                }
                t_info->queue_count -= complete_count;
                cnt -= complete_count;
                break;
        }
}

void *sub_worker(void *threadid)
{
        long tid = (long)threadid;
        struct thread_info_t *t_info = &th_info[tid];
        struct trace_info_t *trace = t_info->trace;
        struct io_stat_t *io_stat = &t_info->io_stat;
        struct iocb *ioq[MAX_QDEPTH];
        struct io_job *jobq[MAX_QDEPTH];
        int rc;
        int iter = 0;
        int cnt = 0;

        gettimeofday(&io_stat->start_time, NULL);

        while (1) {
                int max = t_info->queue_depth - t_info->queue_count;
                if (!max) {
                        printf(" max = %d queue count = %d \n", max,
                               t_info->queue_count);
                        wait_completion(t_info, t_info->queue_count);

                        // generated by Eunjae
                        if (t_info->queue_count == 0)
                                wait_arrive(t_info);
                        max = t_info->queue_depth - t_info->queue_count;
                }

                cnt = make_jobs(t_info, ioq, jobq, max);
                if (!cnt && trace_eof(trace)) {
                        goto Timeout;
                } else if (cnt > 0) {
                        rc = io_submit(t_info->io_ctx, cnt, ioq);
                        if (rc != cnt && rc < 0) {
                                int i;
                                for (i = 0; i < cnt; i++) {
                                        free(jobq[i]->buf);
                                        free(jobq[i]);
                                }
                        }
                        if (rc > 0)
                                t_info->queue_count += rc;
                }

                if (t_info->queue_count) {
                        wait_completion(t_info, t_info->queue_count);
                        if (t_info->queue_count == 0)
                                wait_arrive(t_info);
                }
                gettimeofday(&io_stat->end_time, NULL);
                io_stat->execution_time =
                        time_since(&io_stat->start_time, &io_stat->end_time);
                if (io_stat->execution_time > trace->timeout &&
                    trace->timeout > 0.0) {
                        goto Timeout;
                }
                if (trace->timeout &&
                    io_stat->execution_time > trace->timeout) {
                        goto Timeout;
                }
                pthread_spin_lock(&trace->trace_lock);
                if (trace->trace_io_cur >= trace->trace_io_cnt) {
                        if (try_trace_reset(trace, io_stat)) {
                                pthread_spin_unlock(&trace->trace_lock);
                                goto Timeout;
                        }
                }
                pthread_spin_unlock(&trace->trace_lock);
        }
Timeout:
        while (t_info->queue_count)
                wait_completion(t_info, t_info->queue_count);

        gettimeofday(&io_stat->end_time, NULL);
        io_stat->execution_time =
                time_since(&io_stat->start_time, &io_stat->end_time);

        pthread_mutex_lock(&t_info->mutex);
        t_info->done = 1;
        pthread_mutex_unlock(&t_info->mutex);

        return NULL;
}

int print_result(int nr_trace, int nr_thread, FILE *fp, int detail)
{
        struct io_stat_t total_stat;
        struct realtime_msg rmsg;
        int i, j;
        int per_thread = nr_thread / nr_trace;
        double progress_percent = 0.0;
        key_t server_qkey;
        int server_qid;

        memset(&total_stat, 0x00, sizeof(struct io_stat_t));
        for (i = 0; i < nr_trace; i++) {
                struct io_stat_t io_stat_dst;
                struct trace_info_t *trace = &traces[i];
                memset(&io_stat_dst, 0x00, sizeof(struct io_stat_t));

                for (j = 0; j < per_thread; j++) {
                        int th_num = i * per_thread + j;
                        struct io_stat_t *io_stat_src =
                                &th_info[th_num].io_stat;

                        pthread_spin_lock(&io_stat_src->stat_lock);

                        io_stat_dst.latency_sum += io_stat_src->latency_sum;
                        io_stat_dst.latency_sum_sqr +=
                                io_stat_src->latency_sum_sqr;

                        if (!j) {
                                io_stat_dst.latency_min =
                                        io_stat_src->latency_min;
                                io_stat_dst.latency_max =
                                        io_stat_src->latency_max;
                        } else {
                                if (io_stat_src->latency_min <
                                    io_stat_dst.latency_min)
                                        io_stat_dst.latency_min =
                                                io_stat_src->latency_min;
                                if (io_stat_src->latency_max >
                                    io_stat_dst.latency_max)
                                        io_stat_dst.latency_max =
                                                io_stat_src->latency_max;
                        }

                        io_stat_dst.latency_count += io_stat_src->latency_count;
                        io_stat_dst.total_operations +=
                                io_stat_src->total_operations;
                        io_stat_dst.total_bytes += io_stat_src->total_bytes;
                        io_stat_dst.total_rbytes += io_stat_src->total_rbytes;
                        io_stat_dst.total_wbytes += io_stat_src->total_wbytes;
                        io_stat_dst.cur_bytes += io_stat_src->cur_bytes;
                        io_stat_dst.cur_rbytes += io_stat_src->cur_rbytes;
                        io_stat_dst.cur_wbytes += io_stat_src->cur_wbytes;
                        io_stat_dst.time_diff += io_stat_src->time_diff;
                        io_stat_dst.time_diff_cnt += io_stat_src->time_diff_cnt;

                        io_stat_src->cur_bytes = 0;
                        io_stat_src->cur_rbytes = 0;
                        io_stat_src->cur_wbytes = 0;

                        io_stat_dst.total_error_bytes +=
                                io_stat_src->total_error_bytes;
                        io_stat_dst.execution_time +=
                                io_stat_src->execution_time;
                        pthread_spin_unlock(&io_stat_src->stat_lock);
                }

                if (detail) {
                        double sum_sqr;
                        double mean;
                        double variance;

                        sprintf(total_results.results.per_trace[i].name, "%s",
                                traces[i].tracename);
                        io_stat_dst.execution_time =
                                io_stat_dst.execution_time / per_thread;
                        total_results.results.per_trace[i].stats.exec_time =
                                io_stat_dst.execution_time;
                        total_results.results.per_trace[i].issynthetic =
                                traces[i].synthetic;

                        if (traces[i].synthetic) {
                                total_results.results.per_trace[i]
                                        .synthetic.working_set_size =
                                        traces[i].working_set_size;
                                total_results.results.per_trace[i]
                                        .synthetic.utilization =
                                        traces[i].utilization;
                                total_results.results.per_trace[i]
                                        .synthetic.touched_working_set_size =
                                        traces[i].working_set_size *
                                        traces[i].utilization / 100;
                                total_results.results.per_trace[i]
                                        .synthetic.io_size =
                                        traces[i].io_size / KB;
                        }

                        mean = (double)io_stat_dst.latency_sum /
                               io_stat_dst.latency_count;
                        sum_sqr = io_stat_dst.latency_sum_sqr;
                        variance = (sum_sqr - io_stat_dst.latency_sum * mean) /
                                   (io_stat_dst.latency_count - 1);

                        total_results.results.per_trace[i].stats.avg_lat = mean;
                        total_results.results.per_trace[i].stats.avg_lat_var =
                                variance;
                        total_results.results.per_trace[i].stats.lat_min =
                                io_stat_dst.latency_min;
                        total_results.results.per_trace[i].stats.lat_max =
                                io_stat_dst.latency_max;
                        total_results.results.per_trace[i].stats.iops =
                                io_stat_dst.latency_count /
                                io_stat_dst.execution_time;

                        total_results.results.per_trace[i].stats.total_bw =
                                io_stat_dst.execution_time ?
                                        (double)io_stat_dst.total_bytes / MB /
                                                io_stat_dst.execution_time :
                                        0;

                        total_results.results.per_trace[i].stats.read_bw =
                                io_stat_dst.execution_time ?
                                        (double)io_stat_dst.total_rbytes / MB /
                                                io_stat_dst.execution_time :
                                        0;

                        total_results.results.per_trace[i].stats.write_bw =
                                io_stat_dst.execution_time ?
                                        (double)io_stat_dst.total_wbytes / MB /
                                                io_stat_dst.execution_time :
                                        0;

                        total_results.results.per_trace[i].stats.total_traffic =
                                (double)io_stat_dst.total_bytes / MB;
                        total_results.results.per_trace[i].stats.read_traffic =
                                (double)io_stat_dst.total_rbytes / MB;
                        total_results.results.per_trace[i].stats.write_traffic =
                                (double)io_stat_dst.total_wbytes / MB;
                        total_results.results.per_trace[i].stats.read_ratio =
                                (double)io_stat_dst.total_bytes ?
                                        (double)io_stat_dst.total_wbytes /
                                                (double)io_stat_dst.total_bytes :
                                        0;

                        total_results.results.per_trace[i]
                                .stats.total_avg_req_size =
                                io_stat_dst.latency_count ?
                                        (double)io_stat_dst.total_bytes /
                                                io_stat_dst.latency_count / KB :
                                        0;
                        total_results.results.per_trace[i]
                                .stats.read_avg_req_size =
                                io_stat_dst.latency_count ?
                                        (double)io_stat_dst.total_rbytes /
                                                io_stat_dst.latency_count / KB :
                                        0;
                        total_results.results.per_trace[i]
                                .stats.write_avg_req_size =
                                io_stat_dst.latency_count ?
                                        (double)io_stat_dst.total_wbytes /
                                                io_stat_dst.latency_count / KB :
                                        0;
                        total_results.results.per_trace[i].trace_reset_count =
                                trace->trace_repeat_count;
                }

                if (!i) {
                        total_stat.latency_min = io_stat_dst.latency_min;
                        total_stat.latency_max = io_stat_dst.latency_max;
                } else {
                        if (io_stat_dst.latency_min < total_stat.latency_min)
                                total_stat.latency_min =
                                        io_stat_dst.latency_min;
                        if (io_stat_dst.latency_max > total_stat.latency_max)
                                total_stat.latency_max =
                                        io_stat_dst.latency_max;
                }

                total_stat.total_bytes += io_stat_dst.total_bytes;
                total_stat.total_rbytes += io_stat_dst.total_rbytes;
                total_stat.total_wbytes += io_stat_dst.total_wbytes;
                total_stat.cur_bytes += io_stat_dst.cur_bytes;
                total_stat.cur_rbytes += io_stat_dst.cur_rbytes;
                total_stat.cur_wbytes += io_stat_dst.cur_wbytes;
                total_stat.latency_count += io_stat_dst.latency_count;
                total_stat.latency_sum += io_stat_dst.latency_sum;
                total_stat.latency_sum_sqr += io_stat_dst.latency_sum_sqr;
                total_stat.time_diff += io_stat_dst.time_diff;
                total_stat.time_diff_cnt += io_stat_dst.time_diff_cnt;

                pthread_spin_lock(&trace->trace_lock);
                double temp_percent =
                        (double)(trace->trace_io_cur +
                                 (trace->trace_io_cnt *
                                  (trace->trace_repeat_count - 1))) *
                        100 / (trace->trace_io_cnt * trace->trace_repeat_num);
                pthread_spin_unlock(&trace->trace_lock);
                if (temp_percent > progress_percent)
                        progress_percent = temp_percent;
        }

        if (detail) {
                double sum_sqr;
                double mean;
                double variance;

                mean = total_stat.latency_count ?
                               (double)total_stat.latency_sum /
                                       total_stat.latency_count :
                               0;
                sum_sqr = total_stat.latency_sum_sqr;
                variance = (sum_sqr - total_stat.latency_sum * mean) /
                           (total_stat.latency_count - 1);

                total_results.results.aggr_result.stats.exec_time =
                        execution_time;
                total_results.results.aggr_result.stats.avg_lat = mean;
                total_results.results.aggr_result.stats.avg_lat_var = variance;
                total_results.results.aggr_result.stats.lat_min =
                        total_stat.latency_min;
                total_results.results.aggr_result.stats.lat_max =
                        total_stat.latency_max;

                total_results.results.aggr_result.stats.iops =
                        execution_time ? (double)total_stat.latency_count /
                                                 execution_time :
                                         0;

                total_results.results.aggr_result.stats.total_bw =
                        execution_time ? (double)total_stat.total_bytes / MB /
                                                 execution_time :
                                         0;
                total_results.results.aggr_result.stats.read_bw =
                        execution_time ? (double)total_stat.total_rbytes / MB /
                                                 execution_time :
                                         0;
                total_results.results.aggr_result.stats.write_bw =
                        execution_time ? (double)total_stat.total_wbytes / MB /
                                                 execution_time :
                                         0;

                total_results.results.aggr_result.stats.total_traffic =
                        (double)total_stat.total_bytes / MB;
                total_results.results.aggr_result.stats.read_traffic =
                        (double)total_stat.total_rbytes / MB;
                total_results.results.aggr_result.stats.write_traffic =
                        (double)total_stat.total_wbytes / MB;
                total_results.results.aggr_result.stats.read_ratio =
                        (double)total_stat.total_wbytes ?
                                (double)total_stat.total_rbytes /
                                        (double)total_stat.total_wbytes :
                                0;

                total_results.results.aggr_result.stats.total_avg_req_size =
                        total_stat.latency_count ?
                                (double)total_stat.total_bytes /
                                        total_stat.latency_count / KB :
                                0;
                total_results.results.aggr_result.stats.read_avg_req_size =
                        total_stat.latency_count ?
                                (double)total_stat.total_rbytes /
                                        total_stat.latency_count / KB :
                                0;
                total_results.results.aggr_result.stats.write_avg_req_size =
                        total_stat.latency_count ?
                                (double)total_stat.total_wbytes /
                                        total_stat.latency_count / KB :
                                0;
        } else {
                double avg_bw, cur_bw;
                double latency;
                double avg_time_diff;
                double period_time;
                struct timeval cur_tv;
                static unsigned long long total_bytes;

                gettimeofday(&cur_tv, NULL);
                period_time = time_since(&tv_end, &cur_tv);

                gettimeofday(&tv_end, NULL);
                execution_time = time_since(&tv_start, &tv_end);

                if (execution_time) {
                        avg_bw = (double)total_stat.total_bytes / MB /
                                 execution_time;
                } else {
                        avg_bw = 0;
                }

                if (period_time) {
                        cur_bw =
                                (double)total_stat.cur_bytes / MB / period_time;
                } else {
                        cur_bw = 0;
                }

                if (total_stat.latency_count) {
                        latency = (double)total_stat.latency_sum /
                                  total_stat.latency_count;
                } else {
                        latency = 0;
                }

                if (total_stat.time_diff_cnt) {
                        avg_time_diff = (double)total_stat.time_diff /
                                        total_stat.time_diff_cnt / 1000;
                } else {
                        avg_time_diff = 0;
                }

                if (total_bytes < total_stat.total_bytes)
                        total_bytes = total_stat.total_bytes;

                sprintf(key_pathname, "%s_%d", MSGQ_KEY_PATHNAME, getpid());
                if ((server_qkey = ftok(key_pathname, PROJECT_ID)) < 0) {
                        perror("ftok: server_qkey");
                        goto no_msg;
                }
                if ((server_qid = msgget(server_qkey, 0)) < 0) {
                        perror("msgget: server_qid");
                        goto no_msg;
                }

                memset(&rmsg, 0, sizeof(struct realtime_msg));

                rmsg.mtype = 1;
                rmsg.log.time = execution_time;
                rmsg.log.avg_bw = avg_bw;
                rmsg.log.cur_bw = cur_bw;
                rmsg.log.lat = latency;
                rmsg.log.time_diff = avg_time_diff;

                if (timeout) {
                        rmsg.log.type = TIMEOUT;
                        rmsg.log.remaining = timeout - execution_time;

                } else if (wanted_io_count) {
                        long long remaining_bytes = wanted_io_count * io_size -
                                                    total_stat.total_bytes;
                        double remaining_time = remaining_bytes / MB / avg_bw;

                        rmsg.log.type = WANTED_IO_COUNT;
                        rmsg.log.remaining = remaining_time;
                        rmsg.log.remaining_percentage =
                                (double)remaining_bytes /
                                (wanted_io_count * io_size) * 100;
                } else {
                        rmsg.log.type = NONE;
                        rmsg.log.remaining =
                                execution_time / progress_percent * 100 -
                                execution_time;
                        rmsg.log.remaining_percentage =
                                (double)100 - progress_percent;
                }

                if (msgsnd(server_qid, &rmsg, sizeof(struct realtime_log), 0) <
                    0)
                        perror("msgsnd");
        no_msg:
                if (log_count == 0)
                        fprintf(log_fp,
                                "#ExecTime\tAvgBW\tCurBw\tI/O Issued\n");

                fprintf(log_fp, "%f\t%f\t%f\t%f\n", execution_time, avg_bw,
                        cur_bw, (double)total_stat.total_bytes / MB);
                log_count++;
                fflush(fp);
        }
}

#define ARG_QDEPTH 1
#define ARG_THREAD 2
#define ARG_OUTPUT 3
#define ARG_TIMEOUT 4
#define ARG_REPEAT 5
#define ARG_DEV 6
#define ARG_TRACE 7

void usage_help()
{
        printf("\n Invalid command!!\n");
        printf(" Usage:\n\n");
        printf(" 1. Using Real Trace \n");
        printf(" #./trace_replay qdepth per_thread output timeout trace_repeat devicefile tracefile1 timescale1 0 0 tracefile2 timescale2 0 0 ...\n");
        printf(" #./trace_replay 32 2 result.txt 60 1 /dev/sdb1 trace.dat 1.0 0 0 trace.dat 0.5 0 0\n\n");

        printf(" 2. Using Synthetic Workload \n");
        printf(" #./trace_replay qdepth per_thread output timeout trace_repeat synth_type wss utilization iosize \n");
        printf(" rand_read rand_write rand_mixed seq_read seq_write seq_mixed \n");
        printf(" wss (in MB unit)\n");
        printf(" utilization (in pecent unit)\n");
        printf(" iosize (in KB unit)\n");
        printf("\n");
        printf(" #./trace_replay 32 2 result.txt 60 1 /dev/sdb1 rand_write 128 10 4\n\n");
}

int remove_lastchars(FILE *fp, int len)
{
        int position;

        fseek(fp, -len, SEEK_END);
        position = ftell(fp);
        ftruncate(fileno(fp), position);

        return position;
}

void finalize()
{
        struct realtime_msg rmsg;
        struct total_results *shm_ptr;
        struct sembuf asem[1];
        key_t server_qkey, server_shmkey, server_semkey;
        int server_qid, server_shmid, signal_sem;

        gettimeofday(&tv_end, NULL);
        timeval_subtract(&tv_result, &tv_end, &tv_start);
        execution_time = time_since(&tv_start, &tv_end);

        print_result(nr_trace, nr_thread, stdout, 1);

        fclose(log_fp);

        sprintf(key_pathname, "%s_%d", MSGQ_KEY_PATHNAME, getpid());
        if ((server_qkey = ftok(key_pathname, PROJECT_ID)) < 0) {
                perror("ftok: server_qkey");
                goto no_msgq;
        }
        if ((server_qid = msgget(server_qkey, 0)) < 0) {
                perror("msgget: server_qid");
                goto no_msgq;
        }

        rmsg.mtype = 1;
        rmsg.log.type = FIN;

        if (msgsnd(server_qid, &rmsg, sizeof(struct realtime_log), 0) < 0)
                perror("msgsnd");
no_msgq:
        sprintf(key_pathname, "%s_%d", SEM_KEY_PATHNAME, getpid());
        if ((server_semkey = ftok(key_pathname, PROJECT_ID)) < 0) {
                perror("ftok: server_semkey");
                goto no_shm;
        }
        if ((signal_sem = semget(server_semkey, 1, 0)) < 0) {
                perror("semget: signal_sem");
                goto no_shm;
        }

        sprintf(key_pathname, "%s_%d", SHM_KEY_PATHNAME, getpid());
        if ((server_shmkey = ftok(key_pathname, PROJECT_ID)) < 0) {
                perror("ftok: server_shmkey");
                goto no_shm;
        }
        if ((server_shmid = shmget(server_shmkey, sizeof(struct total_results),
                                   0)) < 0) {
                perror("shmget: server_shmid");
                goto no_shm;
        }
        if ((long)(shm_ptr = (struct total_results *)shmat(server_shmid, NULL,
                                                           0)) == -1) {
                perror("shmat: shm_ptr");
                goto no_shm;
        }

        asem[0].sem_num = 0;
        asem[0].sem_op = 0;
        asem[0].sem_flg = 0;

        *shm_ptr = total_results;

        asem[0].sem_op = 1;
        if (semop(signal_sem, asem, 1) < 0)
                perror("semop: signal_sem");
no_shm:
        fprintf(stdout, "\n Finalizing Trace Replayer \n");
}

int trace_io_put(char *line, struct trace_info_t *trace, int qdepth)
{
        struct trace_io_req *io;
        struct trace_io_req *new_io;
        int start;
        int i, j, k;
        double arrival_time;
        int devno;
        int blkno;
        int bcount;
        unsigned int flags;

        if (trace->trace_buf_size <= trace->trace_io_cnt) {
                trace->trace_buf_size *= 2;
                trace->trace_buf = realloc(trace->trace_buf,
                                           sizeof(struct trace_io_req) *
                                                   trace->trace_buf_size);
        }
AAA:
        if (sscanf(line, "%lf %d %d %d %x\n", &arrival_time, &devno, &blkno,
                   &bcount, &flags) != 5) {
                fprintf(stderr,
                        "Wrong number of arguments for I/O trace event type\n");
                fprintf(stderr, "line: %s", line);
                return -1;
        }
        start = (trace->trace_io_cnt - qdepth * nr_thread > 0) ?
                        trace->trace_io_cnt - qdepth * nr_thread :
                        0;
        for (i = start; i < trace->trace_io_cnt; i++) {
                io = &trace->trace_buf[i];

                if (io->devno == devno) {
                        if (blkno < io->blkno && (blkno + bcount) > io->blkno &&
                            (blkno + bcount) < (io->blkno + io->bcount)) {
                                bcount = io->blkno - blkno;
                        } else if (blkno <= io->blkno &&
                                   (blkno + bcount) >=
                                           (io->blkno + io->bcount)) {
                                io->blkno = blkno;
                                io->bcount = bcount;
                                if (fgets(line, 200, trace->trace_fp) == NULL) {
                                        return -1;
                                }
                                goto AAA;
                        } else if (blkno >= io->blkno &&
                                   (blkno + bcount) <=
                                           (io->blkno + io->bcount)) {
                                if (fgets(line, 200, trace->trace_fp) == NULL) {
                                        return -1;
                                }
                                goto AAA;
                        } else if (blkno > io->blkno &&
                                   blkno < (io->blkno + io->bcount) &&
                                   (blkno + bcount) >
                                           (io->blkno + io->bcount)) {
                                bcount = bcount -
                                         (io->blkno + io->bcount - blkno);
                                blkno = io->blkno + io->bcount;
                        }
                }
        }
        new_io = &trace->trace_buf[trace->trace_io_cnt];
        new_io->arrival_time = arrival_time;
        new_io->devno = devno;
        new_io->bcount = bcount;
        new_io->blkno = blkno;
        new_io->flags = flags;
        trace->trace_io_cnt++;

        return 0;
}

void main_worker()
{
        struct thread_info_t *t_info;
        int i;

        while (1) {
                int done = 0;
                int position;

                for (i = 0; i < nr_thread; i++) {
                        t_info = &th_info[i];
                        pthread_mutex_lock(&t_info->mutex);
                        done += t_info->done;
                        pthread_mutex_unlock(&t_info->mutex);
                }

                if (done == nr_thread)
                        break;

                print_result(nr_trace, nr_thread, stdout, 0);

                usleep(REFRESH_SLEEP);
        }

        printf(" main worker has been finished ... \n");
}

void synthetic_mix(struct trace_info_t *trace)
{
        int i;
        struct timeval cur_tv;

        if (!trace->synth_rand)
                return;

        if (!trace->synthetic)
                return;

        gettimeofday(&cur_tv, NULL);
        sgenrand(cur_tv.tv_sec);

        for (i = 0; i < trace->trace_io_cnt; i++) {
                struct trace_io_req *req1, *req2;
                struct trace_io_req temp;
                int j = i;

                req1 = &trace->trace_buf[i];
                while (j == i) {
                        j = RND(trace->trace_io_cnt);
                }
                req2 = &trace->trace_buf[j];

                memcpy(&temp, req1, sizeof(struct trace_io_req));
                memcpy(req1, req2, sizeof(struct trace_io_req));
                memcpy(req2, &temp, sizeof(struct trace_io_req));
        }
}

void synthetic_gen(struct trace_info_t *trace)
{
        int i;

        trace->trace_io_cnt = trace->working_set_pages / trace->io_pages / 100 *
                              trace->utilization;
        trace->trace_io_cur = 0;
        trace->trace_timescale = 0.0;

        trace->trace_buf =
                malloc(sizeof(struct trace_io_req) * trace->trace_io_cnt);

        for (i = 0; i < trace->trace_io_cnt; i++) {
                struct trace_io_req *req = &trace->trace_buf[i];
                req->arrival_time = i * 1.0;
                req->devno = 0;
                req->blkno = i * trace->io_pages * SPP;
                req->bcount = trace->io_pages * SPP;

                if (trace->synth_write)
                        req->flags = 0;
                else if (trace->synth_read)
                        req->flags = 1;
                else {
                        if (RND(100) < 50)
                                req->flags = 0;
                        else
                                req->flags = 1;
                }
        }

        synthetic_mix(trace);
}

int destroy(pthread_t *threads, int qdepth)
{
        int t, i;

        for (t = 0; t < nr_trace; t++) {
                trace_set_eof(&traces[t]);
        }

        for (t = 0; t < nr_thread; t++) {
                pthread_join(threads[t], NULL);

                pthread_spin_destroy(&th_info[t].io_stat.stat_lock);
                pthread_mutex_destroy(&th_info[t].mutex);
                pthread_cond_destroy(&th_info[t].cond_sub);
                pthread_cond_destroy(&th_info[t].cond_main);
                io_queue_release(th_info[t].io_ctx);

                for (i = 0; i < qdepth; i++) {
                        free(th_info[t].th_buf[i]);
                        free(th_info[t].th_jobs[i]);
                }
                disk_close(th_info[t].fd);
        }

        for (t = 0; t < nr_trace; t++) {
                pthread_spin_destroy(&traces[i].trace_lock);
                if (!traces[t].synthetic) {
                        fclose(traces[t].trace_fp);
                }
                free(traces[t].trace_buf);
                disk_close(traces[t].fd);
        }

        finalize();
}

void sig_handler(int signum)
{
        printf("Received signal %d\n", signum);

        destroy(threads, qdepth);

        signal(SIGINT, SIG_DFL);
        exit(0);
}

#ifdef USE_RAND_BUF
void fill_rand_buf()
{
        int i;

        g_buf = allocate_aligned_buffer(io_size);
        if (g_buf == NULL) {
                printf(" Malloc error \n");
                exit(0);
        }

        for (i = 0; i < io_size; i += sizeof(int)) {
                unsigned int *p = &g_buf[i];
                *p = RND(io_size);
                if (i <= 12)
                        printf(" %u %u\n", *p, io_size);
        }
}
#endif

void *trace_loader(void *data)
{
        struct trace_info_t *trace = (struct trace_info_t *)data;
        char line[201];

        while (1) {
                if (fgets(line, 200, trace->trace_fp) == NULL) {
                        break;
                }
                if (trace_io_put(line, trace, qdepth))
                        continue;
        }

        return NULL;
}

#define EXT_ARG_NUM 4
#ifndef UNIT_TEST
int main(int argc, char **argv)
{
        pthread_t trace_loader_thread[MAX_THREADS];
        int rc;
        int i;
        long t;
        int open_flags;
        int argc_offset = ARG_TRACE;
        int per_thread;
        int repeat;
        char line[201];

        if ((argc - argc_offset) % EXT_ARG_NUM != 0) {
                usage_help();
                return -1;
        }
        nr_trace = (argc - argc_offset) / EXT_ARG_NUM;

        if (nr_trace < 1) {
                usage_help();
                return 0;
        }

        per_thread = atoi(argv[ARG_THREAD]);
        if (per_thread < 1 || per_thread * nr_trace > MAX_THREADS) {
                printf(" invalid per thread num = %d \n", per_thread);
                return -1;
        }
        nr_thread = nr_trace * per_thread;

        if (nr_thread < 1 || nr_thread > MAX_THREADS) {
                printf(" invalid thread num = %d \n", nr_thread);
                return -1;
        }

        qdepth = atoi(argv[ARG_QDEPTH]);
        if (qdepth > MAX_QDEPTH)
                qdepth = MAX_QDEPTH;
        if (qdepth == 0)
                qdepth = 1;

        timeout = atof(argv[ARG_TIMEOUT]);
        repeat = atoi(argv[ARG_REPEAT]);
        if (timeout > 0.0) {
                repeat = 1;
        }
        if (repeat == 0)
                repeat = 1;

        sprintf(line, "%s.log", argv[ARG_OUTPUT]);
        log_fp = fopen(line, "w");
        if (log_fp == NULL) {
                printf(" open file %s error \n", line);
                return -1;
        }

        total_results.config.qdepth = qdepth;
        total_results.config.timeout = timeout;
        total_results.config.nr_trace = nr_trace;
        total_results.config.nr_thread = nr_thread;
        total_results.config.per_thread = per_thread;
        sprintf(total_results.config.result_file, "%s", argv[ARG_OUTPUT]);

        for (i = 0; i < nr_trace; i++) {
                struct trace_info_t *trace = &traces[i];

                memset(trace, 0x00, sizeof(struct trace_info_t));

                strcpy(trace->tracename, argv[argc_offset + i * EXT_ARG_NUM]);
                strcpy(trace->filename, argv[ARG_DEV]);

                open_flags = O_RDWR | O_DIRECT;
                trace->fd = disk_open(trace->filename, open_flags);
                if (trace->fd < 0)
                        return -1;

                pthread_spin_init(&trace->trace_lock, 0);
                ioctl(trace->fd, BLKGETSIZE64, &trace->total_capacity);
                trace->total_pages = trace->total_capacity / PAGE_SIZE;
                trace->total_pages = trace->total_pages / nr_trace;
                trace->total_sectors = trace->total_pages * SPP;
                trace->total_capacity = trace->total_pages * PAGE_SIZE;
                trace->start_partition = trace->total_capacity * i;
                trace->start_page = trace->start_partition / PAGE_SIZE;
                trace->timeout = timeout;
                trace->trace_repeat_count = 1;
                trace->trace_repeat_num = repeat;

                // synthetic workload
                if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM], "rand") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                            "rand_write") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM], "rand_read") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                            "rand_mixed") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM], "seq") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM], "seq_write") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM], "seq_read") ||
                    !strcmp(argv[argc_offset + i * EXT_ARG_NUM], "seq_mixed")) {
                        trace->synthetic = 1;
                        trace->synth_rand = 1;
                        trace->synth_write = 1;
                        trace->synth_read = 0;
                        trace->synth_mixed = 0;

                        if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                    "rand") ||
                            !strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                    "rand_write")) {
                                trace->synth_rand = 1;
                                trace->synth_write = 1;
                                trace->synth_read = 0;
                                trace->synth_mixed = 0;
                                printf(" Synthetic workload: Random Write \n");
                        } else if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                           "rand_read")) {
                                trace->synth_rand = 1;
                                trace->synth_write = 0;
                                trace->synth_read = 1;
                                trace->synth_mixed = 0;
                                printf(" Synthetic workload: Random Read \n");
                        } else if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                           "rand_mixed")) {
                                trace->synth_rand = 1;
                                trace->synth_write = 0;
                                trace->synth_read = 0;
                                trace->synth_mixed = 1;
                                printf(" Synthetic workload: Random Mixed Read Write\n");
                        } else if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                           "seq_write") ||
                                   !strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                           "seq")) {
                                trace->synth_rand = 0;
                                trace->synth_write = 1;
                                trace->synth_read = 0;
                                trace->synth_mixed = 0;
                                printf(" Synthetic workload: Sequential Write\n");
                        } else if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                           "seq_read")) {
                                trace->synth_rand = 0;
                                trace->synth_write = 0;
                                trace->synth_read = 1;
                                trace->synth_mixed = 0;
                                printf(" Synthetic workload: Sequential Read\n");
                        } else if (!strcmp(argv[argc_offset + i * EXT_ARG_NUM],
                                           "seq_mixed")) {
                                trace->synth_rand = 0;
                                trace->synth_write = 0;
                                trace->synth_read = 0;
                                trace->synth_mixed = 1;
                                printf(" Synthetic workload: Sequential Mixed Read Write\n");
                        }

                        trace->io_size = atoi(
                                argv[argc_offset + i * EXT_ARG_NUM + 3]); // KB
                        trace->io_size *= KB;

                        if (trace->io_size > MAX_BYTES) {
                                printf(" io size cannot be greater than %dKB\n",
                                       MAX_BYTES / KB);
                                return -1;
                        }

                        if (trace->io_size == 0)
                                trace->io_size = 4096;
                        io_size = trace->io_size;

#ifdef USE_RAND_BUF
                        fill_rand_buf();
#endif

                        trace->io_pages = trace->io_size / PAGE_SIZE;
                        trace->working_set_size =
                                atoi(argv[argc_offset + i * EXT_ARG_NUM + 1]);
                        trace->working_set_size =
                                (int)((long long)trace->working_set_size * MB /
                                      io_size * io_size / MB);
                        trace->working_set_pages =
                                trace->working_set_size * MB / PAGE_SIZE;

                        if (trace->working_set_size <= 0 ||
                            trace->working_set_pages >= trace->total_pages) {
                                printf(" Invalid working set size value = %dMB (device capacity = %dMB)\n",
                                       trace->working_set_size,
                                       (int)PAGE_TO_MB(trace->total_pages));
                                return -1;
                        }

                        trace->utilization =
                                atoi(argv[argc_offset + i * EXT_ARG_NUM + 2]);
                        if (trace->utilization <= 0 ||
                            trace->utilization > 100) {
                                printf(" Invalid utilization value = %d \n",
                                       trace->utilization);
                                return -1;
                        }

                        trace->wanted_io_count = trace->working_set_pages /
                                                 trace->io_pages * repeat;
                        wanted_io_count = trace->wanted_io_count;
                        synthetic_gen(trace);

                        printf(" WSS (Working Set Size) = %dMB\n",
                               (int)trace->working_set_size);
                        printf(" I/O Size = %dMB\n",
                               (int)((long long)trace->wanted_io_count *
                                     trace->io_size / MB));
                        if (trace->io_size * KB % PAGE_SIZE) {
                                printf(" Invalid I/O size = %dKB \n",
                                       trace->io_size);
                                usage_help();
                                return 0;
                        }
                        printf(" Request Size = %dKB\n",
                               (int)trace->io_size / KB);

                } else {
                        trace->trace_buf_size = 1024;
                        trace->trace_buf =
                                malloc(sizeof(struct trace_io_req) * 1024);
                        trace->trace_io_cnt = 0;
                        trace->trace_io_cur = 0;
                        trace->trace_timescale =
                                atof(argv[argc_offset + i * EXT_ARG_NUM + 1]);

                        trace->trace_fp =
                                fopen(argv[argc_offset + i * EXT_ARG_NUM], "r");
                        if (trace->trace_fp == NULL) {
                                printf("file open error %s\n",
                                       argv[argc_offset + i * EXT_ARG_NUM]);
                                return -1;
                        }

                        rc = pthread_create(&trace_loader_thread[i], NULL,
                                            trace_loader, (void *)trace);
                        if (rc) {
                                printf("ERROR; return code from pthread_create( is %d\n",
                                       rc);
                                exit(-1);
                        }
                }

                total_results.config.traces[i].start_partition =
                        (double)trace->start_partition / 1024 / 1024 / 1024;
                total_results.config.traces[i].total_size =
                        (double)trace->total_capacity / 1024 / 1024 / 1024;
                total_results.config.traces[i].start_page = trace->start_page;
                total_results.config.traces[i].total_pages =
                        trace->start_page + trace->total_pages;
        }

        for (i = 0; i < nr_trace; i++) {
                struct trace_info_t *trace = &traces[i];
                if (!trace->synthetic)
                        pthread_join(trace_loader_thread[i], NULL);
        }

        for (t = 0; t < nr_thread; t++) {
                struct thread_info_t *t_info = &th_info[t];
                struct trace_info_t *trace = &traces[t / per_thread];
                t_info->trace = trace;

                pthread_mutex_init(&t_info->mutex, NULL);
                pthread_cond_init(&t_info->cond_sub, NULL);
                pthread_cond_init(&t_info->cond_main, NULL);

                memset(&t_info->io_ctx, 0, sizeof(io_context_t));

                t_info->tid = (int)t;
                t_info->queue_depth = qdepth;
                t_info->queue_count = 0;
                t_info->active_count = 0;
                t_info->done = 0;

                t_info->fsync_period = 0;

                open_flags = O_RDWR | O_DIRECT;
                t_info->fd = disk_open(trace->filename, open_flags);
                if (t_info->fd < 0)
                        return -1;

                for (i = 0; i < qdepth; i++) {
                        t_info->th_buf[i] = allocate_aligned_buffer(MAX_BYTES);
                        t_info->th_jobs[i] = malloc(sizeof(struct io_job));
                }
                t_info->buf_cur = 0;

                memset(&t_info->io_stat, 0x00, sizeof(struct io_stat_t));
                pthread_spin_init(&t_info->io_stat.stat_lock, 0);

                io_queue_init(t_info->queue_depth, &t_info->io_ctx);
        }

        for (t = 0; t < nr_thread; t++) {
                rc = pthread_create(&threads[t], NULL, sub_worker, (void *)t);
                if (rc) {
                        printf("ERROR; return code from pthread_create( is %d\n",
                               rc);
                        exit(-1);
                }
        }

        gettimeofday(&tv_start, NULL);
        gettimeofday(&tv_start2, NULL);

        signal(SIGINT, sig_handler);

        /* json file for real time results */
        main_worker();

        destroy(threads, qdepth);

        return 0;
}
#endif

#define N 624
#define M 397
#define MATRIX_A 0x9908b0df /* constant vector a */
#define UPPER_MASK 0x80000000 /* most significant w-r bits */
#define LOWER_MASK 0x7fffffff /* least significant r bits */

/* Tempering parameters */
#define TEMPERING_MASK_B 0x9d2c5680
#define TEMPERING_MASK_C 0xefc60000
#define TEMPERING_SHIFT_U(y) (y >> 11)
#define TEMPERING_SHIFT_S(y) (y << 7)
#define TEMPERING_SHIFT_T(y) (y << 15)
#define TEMPERING_SHIFT_L(y) (y >> 18)

static unsigned long mt[N]; /* the array for the state vector  */
static int mti = N + 1; /* mti==N+1 means mt[N] is not initialized */

/* Initializing the array with a seed */
void sgenrand(seed) unsigned long seed;
{
        int i;

        for (i = 0; i < N; i++) {
                mt[i] = seed & 0xffff0000;
                seed = 69069 * seed + 1;
                mt[i] |= (seed & 0xffff0000) >> 16;
                seed = 69069 * seed + 1;
        }
        mti = N;
}

unsigned long genrand()
{
        unsigned long y;
        /* mag01[x] = x * MATRIX_A  for x=0,1 */

        if (mti >= N) { /* generate N words at one time */
                static unsigned long mag01[2] = { 0x0, MATRIX_A };
                int kk;

                if (mti == N + 1) /* if sgenrand() has not been called, */
                        sgenrand(4357); /* a default initial seed is used   */

                for (kk = 0; kk < N - M; kk++) {
                        y = (mt[kk] & UPPER_MASK) | (mt[kk + 1] & LOWER_MASK);
                        mt[kk] = mt[kk + M] ^ (y >> 1) ^ mag01[y & 0x1];
                }
                for (; kk < N - 1; kk++) {
                        y = (mt[kk] & UPPER_MASK) | (mt[kk + 1] & LOWER_MASK);
                        mt[kk] = mt[kk + (M - N)] ^ (y >> 1) ^ mag01[y & 0x1];
                }
                y = (mt[N - 1] & UPPER_MASK) | (mt[0] & LOWER_MASK);
                mt[N - 1] = mt[M - 1] ^ (y >> 1) ^ mag01[y & 0x1];

                mti = 0;
        }

        y = mt[mti++];
        y ^= TEMPERING_SHIFT_U(y);
        y ^= TEMPERING_SHIFT_S(y) & TEMPERING_MASK_B;
        y ^= TEMPERING_SHIFT_T(y) & TEMPERING_MASK_C;
        y ^= TEMPERING_SHIFT_L(y);

        return y;
}
